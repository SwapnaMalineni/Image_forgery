{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":115146,"sourceType":"datasetVersion","datasetId":59500}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nfrom PIL import Image, ImageChops, ImageEnhance\nimport os\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T06:46:04.025955Z","iopub.execute_input":"2025-02-17T06:46:04.026379Z","iopub.status.idle":"2025-02-17T06:46:08.659118Z","shell.execute_reply.started":"2025-02-17T06:46:04.026345Z","shell.execute_reply":"2025-02-17T06:46:08.658009Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    ela_filename = 'temp_ela.png'\n    \n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality = quality)\n    temp_image = Image.open(temp_filename)\n    \n    ela_image = ImageChops.difference(image, temp_image)\n    \n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 / max_diff\n    \n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    \n    return ela_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Au/Au_ani_00001.jpg'\nImage.open(real_image_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"convert_to_ela_image(real_image_path, 90)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fake_image_path = '/kaggle/input/casia-dataset/casia/CASIA2/Tp/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg'\nImage.open(fake_image_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"convert_to_ela_image(fake_image_path, 90)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare image function\nimage_size = (128, 128)\ndef prepare_image(image_path):\n    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Initialize X and Y as empty lists\nX = []  # List to hold the images\nY = []  # List to hold the labels (0 for fake, 1 for real)\n\n# Process the 'real' images (label = 1)\npath = '/kaggle/input/casia-dataset/CASIA2/Au/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))  # Append to the list\n            Y.append(1)  # Label as real\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\n# Process the 'fake' images (label = 0)\npath = '/kaggle/input/casia-dataset/CASIA2/Tp/'\nfor dirname, _, filenames in os.walk(path):\n    for filename in filenames:\n        if filename.endswith('jpg') or filename.endswith('png'):\n            full_path = os.path.join(dirname, filename)\n            X.append(prepare_image(full_path))  # Append to the list\n            Y.append(0)  # Label as fake\n            if len(Y) % 500 == 0:\n                print(f'Processing {len(Y)} images')\n\n# Convert lists to numpy arrays\nX = np.array(X)\nY = np.array(Y)\n\nprint(f\"Length of X: {len(X)}, Length of Y: {len(Y)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert labels to categorical format\nY = to_categorical(Y, 2)\n\n# Reshape X for CNN input\nX = X.reshape(-1, 128, 128, 3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\nX = X.reshape(-1, 128, 128, 3)\nprint(len(X_train), len(Y_train))\nprint(len(X_val), len(Y_val))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (128, 128, 3)))\n    model.add(MaxPool2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = 'softmax'))\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_model()\nmodel.summary()\nModel: \"sequential\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 30\nbatch_size = 32\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler\n\n# Initialize the learning rate and optimizer\ninit_lr = 1e-4\noptimizer = Adam(learning_rate=init_lr)\n\n# Define the learning rate schedule function\ndef lr_schedule(epoch, lr):\n    decay_rate = init_lr / epochs\n    return init_lr * (1 / (1 + decay_rate * epoch))\n\n# Create the learning rate scheduler callback\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\n# Compile the model with the optimizer\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n\n# Define the EarlyStopping callback\nearly_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=5, verbose=1)\n\n# Fit the model with early stopping\nhist = model.fit(X_train,\n                 Y_train,\n                 batch_size=batch_size,\n                 epochs=epochs,\n                 validation_data=(X_val, Y_val),\n                 callbacks=[early_stopping])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('forgery_abd_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}